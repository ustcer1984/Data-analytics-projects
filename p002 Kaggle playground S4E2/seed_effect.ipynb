{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data background, cleaning and EDA --> [Link](https://www.kaggle.com/code/ustcer1984/obesity-eda-cluster-playground-s4e2)  \n",
    "KNN model scaler tuning --> [Link](https://www.kaggle.com/code/ustcer1984/obesity-prediction-knn-model-scaler-tuning-s4e2)  \n",
    "Ethics concern on model and metric selection --> [Link](https://www.kaggle.com/code/ustcer1984/obesity-ethics-concern-on-model-selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed effect on model performance\n",
    "\n",
    "Just for fun and curiosity, what is the variance of model performance with different random seeds?\n",
    "\n",
    "#### **Plan**\n",
    "\n",
    "- Compare RF, XGB and LGBM models.\n",
    "    - All use default parameters except `random_state`\n",
    "- Study statistical distribution of accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "num_seeds = 10 # number of seeds in our experiment\n",
    "input_path = './'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) # show all columns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme() # I like seaborn default theme\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # suppress warning msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transform\n",
    "df_train_raw = pd.read_csv(input_path + 'train.csv')\n",
    "df_test_raw = pd.read_csv(input_path + 'test.csv')\n",
    "\n",
    "df0 = df_train_raw.copy()\n",
    "df0.drop(columns=['id'], inplace=True)\n",
    "df0.columns = df0.columns.str.lower()\n",
    "df0.rename(columns={'family_history_with_overweight':'history'}, inplace=True)\n",
    "\n",
    "# tranform boolean columns\n",
    "for col in ['history', 'favc', 'smoke', 'scc']:\n",
    "    df0[col] = df0[col].map({'yes': True, 'no': False})\n",
    "\n",
    "# transfer categorical columns\n",
    "df0['gender'] = pd.Categorical(df0['gender'], \n",
    "                               categories=['Male', 'Female'],\n",
    "                               ordered=True)\n",
    "df0['caec'] = pd.Categorical(df0['caec'],\n",
    "                             categories=['Frequently', 'Always', 'no', 'Sometimes'],\n",
    "                             ordered=True)\n",
    "df0['calc'] = pd.Categorical(df0['calc'],\n",
    "                             categories=['Frequently', 'no', 'Sometimes'],\n",
    "                             ordered=True)\n",
    "df0['mtrans'] = pd.Categorical(df0['mtrans'],\n",
    "                               categories=['Walking', 'Bike', 'Motorbike', \n",
    "                                           'Automobile', 'Public_Transportation'],\n",
    "                               ordered=True)\n",
    "df0['nobeyesdad'] = pd.Categorical(df0['nobeyesdad'],\n",
    "                                   categories=['Insufficient_Weight', 'Normal_Weight', \n",
    "                                               'Overweight_Level_I', 'Overweight_Level_II', \n",
    "                                               'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III'], \n",
    "                                   ordered=True)\n",
    "\n",
    "df0['bmi'] = df0['weight'] / np.square(df0['height'])\n",
    "\n",
    "# ordinal encoding all categorical variables\n",
    "df0_ordinal = df0.copy()\n",
    "for col in df0_ordinal.columns:\n",
    "    if df0_ordinal[col].dtype == 'category':\n",
    "        df0_ordinal[col] = df0_ordinal[col].cat.codes\n",
    "\n",
    "# one hot encoding all categorical variables\n",
    "df0_onehot = pd.get_dummies(df0.drop(columns=['nobeyesdad']))\n",
    "\n",
    "# prepare stratify standard column\n",
    "df0_ordinal['stratify'] = np.zeros(df0_ordinal.shape[0])\n",
    "for col in ['gender', 'favc', 'smoke', 'scc']:\n",
    "    df0_ordinal['stratify'] = df0_ordinal['stratify'] * 10 + df0_ordinal[col]\n",
    "df0_ordinal['stratify'] = df0_ordinal['stratify'].convert_dtypes('int')\n",
    "\n",
    "# select X, y\n",
    "X_ordinal = df0_ordinal.drop(columns=['stratify', 'nobeyesdad'])\n",
    "X_onehot = df0_onehot.copy()\n",
    "y = df0_ordinal['nobeyesdad']\n",
    "\n",
    "# split train and validate datasets\n",
    "X_ordinal_train, X_ordinal_val, X_onehot_train, X_onehot_val, y_train, y_val =\\\n",
    "    train_test_split(X_ordinal, X_onehot, y, test_size=0.25,\n",
    "                     stratify=df0_ordinal['stratify'],\n",
    "                     random_state=42)\n",
    "\n",
    "# reset index for all split datasets\n",
    "X_ordinal_train.reset_index(drop=True, inplace=True)\n",
    "X_ordinal_val.reset_index(drop=True, inplace=True)\n",
    "X_onehot_train.reset_index(drop=True, inplace=True)\n",
    "X_onehot_val.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['RF', 'XGB', 'LGBM']\n",
    "model_dict = {'RF': {'model': RandomForestClassifier, 'best_model': 0, 'best_score': 0},\n",
    "              'XGB': {'model': XGBClassifier, 'best_model': 0, 'best_score': 0},\n",
    "              'LGBM': {'model': LGBMClassifier, 'best_model': 0, 'best_score': 0}}\n",
    "model_score = {'RF': [], 'XGB': [], 'LGBM': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13min 17s\n",
      "Wall time: 58.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for seed in range(2000, 2000 + num_seeds):\n",
    "    for model in model_list:\n",
    "        if model == 'LGBM':\n",
    "            clf = model_dict[model]['model'](random_state=seed, n_jobs=-1, verbose=-1, )\n",
    "        else:\n",
    "            clf = model_dict[model]['model'](random_state=seed, n_jobs=-1)\n",
    "        clf.fit(X_onehot_train, y_train)\n",
    "        y_pred = clf.predict(X_onehot_val)\n",
    "        score = metrics.accuracy_score(y_val, y_pred)\n",
    "        model_score[model].append(score)\n",
    "        if score > model_dict[model]['best_score']:\n",
    "            model_dict[model]['best_model'] = clf\n",
    "            model_dict[model]['best_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare test dataset\n",
    "# df1 = df_test_raw.copy()\n",
    "# df_submit = df1[['id']] # reserve id column\n",
    "\n",
    "# df1.drop(columns=['id'], inplace=True)\n",
    "# df1.columns = df1.columns.str.lower()\n",
    "# df1.rename(columns={'family_history_with_overweight':'history'}, inplace=True)\n",
    "\n",
    "# # tranform boolean columns\n",
    "# for col in ['history', 'favc', 'smoke', 'scc']:\n",
    "#     df1[col] = df1[col].map({'yes': True, 'no': False})\n",
    "\n",
    "# # transfer categorical columns\n",
    "# df1['gender'] = pd.Categorical(df1['gender'], \n",
    "#                                categories=['Male', 'Female'],\n",
    "#                                ordered=True)\n",
    "# df1['caec'] = pd.Categorical(df1['caec'],\n",
    "#                              categories=['Frequently', 'Always', 'no', 'Sometimes'],\n",
    "#                              ordered=True)\n",
    "# df1['calc'] = pd.Categorical(df1['calc'],\n",
    "#                              categories=['Frequently', 'no', 'Sometimes'],\n",
    "#                              ordered=True)\n",
    "# df1['mtrans'] = pd.Categorical(df1['mtrans'],\n",
    "#                                categories=['Walking', 'Bike', 'Motorbike', \n",
    "#                                            'Automobile', 'Public_Transportation'],\n",
    "#                                ordered=True)\n",
    "\n",
    "# df1['bmi'] = df1['weight'] / np.square(df1['height'])\n",
    "\n",
    "# # one hot encoding all categorical variables\n",
    "# X_test = pd.get_dummies(df1)\n",
    "\n",
    "# nobeyesdad_list = ['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I', \n",
    "#                    'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II', \n",
    "#                    'Obesity_Type_III']\n",
    "# df_submit['NObeyesdad'] = final_model.predict(X_test)\n",
    "# df_submit['NObeyesdad'] = df_submit['NObeyesdad'].apply(lambda x: nobeyesdad_list[x])\n",
    "\n",
    "# df_submit.to_csv('lgbm_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZZ_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
