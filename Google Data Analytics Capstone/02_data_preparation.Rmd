---
title: "02 Data Preparation"
author: "ZHANG ZHOU"
date: "2023-12-06"
output:
  html_document: 
    highlight: espresso
---

<hr style="border:1px solid lightgrey">

Now we start to take a look at the available data and decide the right tools to use in this project.

\

## Data source

Here is the [data bucket](https://divvy-tripdata.s3.amazonaws.com/index.html).

The data has been made available by Motivate International Inc. under this [license](https://divvybikes.com/data-license-agreement).

The data is stored in `.csv` files according to calender month.

-   For this case study I will use the **latest one year** data, *i.e.*, from Nov/2022 to Oct/2023.

\

Let's take a look at the downloaded files (already unzipped) first:

<center>

![Figure 2.1: Raw data](https://drive.google.com/uc?id=1HpPR3sVApdTnkS12gXMMhnUHbmQiF87_){width="300"}

</center>

\

The file names are uniform and self-0explanatory. It is interesting to find that the file sizes show big variation, so I make a simple plot using Google Sheets as shown below.

<center>

![Figure 2.2: Raw data file size trend](https://drive.google.com/uc?id=1fui4LhUspr12D1Sw8OwH7j5O6fJIc1BF){width="600"}

</center>

\

The file size trend clearly shows seasonal pattern! If [file size is correlated to the number of trips]{style="background-color: gold;"}, then it makes sense as people tends to ride more at summer and less at winter. Of course we cannot reply on file size to conclude, later we will test the hypothesis with the actual trip data inside these files.

[**NOTE**]{style="background-color: lightgrey;"}

-   Above figure includes `Oct/2022` file size data. It is comparable or slightly bigger than `Oct/2023` file, looks like Cyclistic's business size is stable after one year, [no significant growth]{style="background-color: gold;"}. `Oct/2022` data will [**NOT**]{style="color: red;"} be used in the study later.

-   Trend line is added in this figure for better visualization. This trend line is generated by 3 degree polynomial fitting. Actually this model is not suitable though fitting score is high [R^2^ = 0.987]{style="background-color: lightgrey;"}. We should [**NOT**]{style="color: red;"} use this fitting to forecast the trend. Sine wave function model fitting is more suitable here, but is not included in Google spreadsheet plot option. Here I choose polynomial trend fitting for convenience only.

------------------------------------------------------------------------

## Tool Selection

We can use [Google Sheets]{style="background-color: lightgrey;"} or [Excel]{style="background-color: lightgrey;"} to open `.csv` file, however they may be not suitable for data cleaning and analysis in this study due to too big file size.

Here we will use [SQL (BigQuery)]{style="background-color: lightgrey;"} and [R (RStudio)]{style="background-color: lightgrey;"} for data cleaning and transformation.

[R (RStudio)]{style="background-color: lightgrey;"} will be the main tool for data visualization. [Tableau]{style="background-color: lightgrey;"} may also be used if necessary.

This document is prepared with [RMarkdown (RStudio)]{style="background-color: lightgrey;"}. Final presentation will be made with [Google Slides]{style="background-color: lightgrey;"} or [PowerPoint]{style="background-color: lightgrey;"}.

Finally I also put [Notepad++]{style="background-color: lightgrey;"} in my tool box. I highly recommend this tool as a fast way to preview text files especially those super large ones.

------------------------------------------------------------------------

## Environment setup

Due to the size of these \`.csv' files, I don't recommend to directly import into database or R as there can be many kinds of issues:

-   If the `.csv` file is [exported from another software]{style="background-color: gold;"} (e.g. scientific measurement machine), then

    -   **May contain many lines of meta data.**\
        I have seen measurement data with more than 1000 lines of meta data for detailed machine configuration and sensor / detector settings. What makes it worse is that these meta data lines can be anywhere before, after, or in between actual data.

    -   **May use special delimiter other than comma `,`**

    -   **May use special character(s) to represent `NA` value.**

    -   **Data may not be displayed in table format.**\
        I have experience with one measurement machine which exports all data in a single column. Data columns are separated by empty lines. First 2 rows of each column are header and unit. Using 3rd party software or programming language to process these data, default `.csv` import method will not work.

    -   **One file may contain multiple tables.**

-   If the `.csv` file is [saved from a working spreadsheet]{style="background-color: gold;"}, then

    -   Need to find out the **data range** to be imported.

    -   Be careful for any **typo** or **misaligned cells**.

\

Consider the file size, I also don't recommend to directly open them by spreadsheet.

-   [Excel]{style="background-color: lightgrey;"} can only handle one million rows.

-   Even if the data size is less than one million rows, handling big file by [Excel]{style="background-color: lightgrey;"} can be slow and sometimes hang.

\

#### **File inspection by [Notepad++]{style="background-color: lightgrey;"}**

Let's take a look at the raw data file by [Notepad++]{style="background-color: lightgrey;"}:

<center>

![Figure 2.3: [Notepad++]{style="background-color: lightgrey;"} preview of Dec/2022 data file](image/02_003.png){width="75%"}

</center>

\

From this above preview we can see the data files are well formatted `.csv` containing data in table form.

-   The first row contains headers.

-   The rest rows contain data values.

-   No extra rows at the tail. (You can simply drag to the end to see.)

-   Total \~181K rows in the Dec/2022 file, whose size is the smallest among all the 12 files. So the whole year data is more than 1 million rows, cannot be handled by [Excel]{style="background-color: lightgrey;"}.

-   Simply dragging through this file we can easily find short lines with `NA` values, as shown in the figure below. This file does NOT use special character(s) to represent `NA`.

<center>

![Figure 2.4: [Notepad++]{style="background-color: lightgrey;"} preview of `NA` value in the file](image/02_004.png){width="75%"}

</center>

\

By sampling more data files we can see they all show same format.\
Now we can conclude that these files can be imported without special treatment.

\

#### [**BigQuery**]{style="background-color: lightgrey;"} **environment setup**

I use `BigQuery SANDBOX` SQL database for this case study.

New project named `data-analytics-case1` is created, and all `.csv` files are uploaded to dataset `raw_data`.

-   `BigQuery` does NOT allow directly upload `.csv` file bigger than 100MB. So I upload them to `Google Drive` first, then import to `BigQuery` from there.

Union all tables into one with below query:

```{sql, eval = FALSE}
SELECT * FROM `data-analytics-case1.raw_data.202211-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202212-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202301-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202302-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202303-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202304-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202305-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202306-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202307-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202308-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202309-divvy-tripdata`
UNION ALL
SELECT * FROM `data-analytics-case1.raw_data.202310-divvy-tripdata`
```

The result is saved as a new table `2211to2310-divvy-tripdata` in dataset `process`.

------------------------------------------------------------------------

## First glimpse of the raw data

Below shows the table schema and description (added by myself) of each field.

```{=html}
<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-ohj6{background-color:#f9f9f9;border-color:#c0c0c0;font-family:Arial, Helvetica, sans-serif !important;font-size:small;
  text-align:left;vertical-align:top}
.tg .tg-kg0h{background-color:#f9f9f9;border-color:inherit;font-family:Arial, Helvetica, sans-serif !important;font-size:small;
  text-align:left;vertical-align:top}
.tg .tg-xjb7{border-color:#c0c0c0;font-family:Arial, Helvetica, sans-serif !important;font-size:small;text-align:left;
  vertical-align:top}
.tg .tg-mdof{border-color:inherit;font-family:Arial, Helvetica, sans-serif !important;font-size:small;font-weight:bold;
  text-align:left;vertical-align:top}
.tg .tg-ak6m{border-color:inherit;font-family:Arial, Helvetica, sans-serif !important;font-size:small;text-align:left;
  vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-mdof">Field name</th>
    <th class="tg-mdof">Type</th>
    <th class="tg-mdof">Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-kg0h">ride_id</td>
    <td class="tg-kg0h">STRING</td>
    <td class="tg-kg0h">Unique id for each ride</td>
  </tr>
  <tr>
    <td class="tg-ak6m">rideable_type</td>
    <td class="tg-ak6m">STRING</td>
    <td class="tg-ak6m">bike type</td>
  </tr>
  <tr>
    <td class="tg-kg0h">started_at</td>
    <td class="tg-kg0h">TIMESTAMP</td>
    <td class="tg-kg0h">trip start time</td>
  </tr>
  <tr>
    <td class="tg-ak6m">ended_at</td>
    <td class="tg-ak6m">TIMESTAMP</td>
    <td class="tg-ak6m">trip end time</td>
  </tr>
  <tr>
    <td class="tg-kg0h">start_station_name</td>
    <td class="tg-kg0h">STRING</td>
    <td class="tg-ohj6"></td>
  </tr>
  <tr>
    <td class="tg-ak6m">start_station_id</td>
    <td class="tg-ak6m">STRING</td>
    <td class="tg-xjb7"></td>
  </tr>
  <tr>
    <td class="tg-kg0h">end_station_name</td>
    <td class="tg-kg0h">STRING</td>
    <td class="tg-ohj6"></td>
  </tr>
  <tr>
    <td class="tg-ak6m">end_station_id</td>
    <td class="tg-ak6m">STRING</td>
    <td class="tg-xjb7"></td>
  </tr>
  <tr>
    <td class="tg-kg0h">start_lat</td>
    <td class="tg-kg0h">STRING</td>
    <td class="tg-kg0h">start latitude</td>
  </tr>
  <tr>
    <td class="tg-ak6m">start_lng</td>
    <td class="tg-ak6m">FLOAT</td>
    <td class="tg-ak6m">start longitude</td>
  </tr>
  <tr>
    <td class="tg-kg0h">end_lat</td>
    <td class="tg-kg0h">FLOAT</td>
    <td class="tg-kg0h">end latitude</td>
  </tr>
  <tr>
    <td class="tg-ak6m">end_lng</td>
    <td class="tg-ak6m">FLOAT</td>
    <td class="tg-ak6m">end longitude</td>
  </tr>
  <tr>
    <td class="tg-kg0h">member_casual</td>
    <td class="tg-kg0h">STRING</td>
    <td class="tg-kg0h">customer type</td>
  </tr>
</tbody>
</table>
</center>
```
Basically each row represents one trip with the data of:

-   Bike type: classic, electric, docked
-   Start and end points info: time, station, coordinate
    -   Coordinate accuracy seems low (round to 2 digits after dismal point) when station info is missing. Maybe the data is calculated from customer mobile app GPS.
    -   Coordinate accuracy seems very high when station info is available. Maybe the data is predefined for each station.
-   Customer type: casual or annual

There is no customer identification data to tell whether 2 trips belong to the same customer. So unfortunately we cannot do analysis like average count of trips by each customer. Also there is no way to tell if there is any customer converted from casual to annual membership in this period.

------------------------------------------------------------------------

## Data cleaning and integrity check

#### **1. Data size and number of `NULL` in each column**

```{sql, eval = FALSE}
SELECT
  *
FROM (
  SELECT
    COUNT(*) AS num_row,
    COUNT(*) - COUNT(ride_id) AS null_ride_id,
    COUNT(*) - COUNT(rideable_type) AS null_rideable_type,
    COUNT(*) - COUNT(started_at) AS null_started_at,
    COUNT(*) - COUNT(ended_at) AS  null_ended_at,
    COUNT(*) - COUNT(start_station_id) AS null_start_id,
    COUNT(*) - COUNT(start_station_name) AS null_start_name,
    COUNT(*) - COUNT(end_station_id) AS null_end_id,
    COUNT(*) - COUNT(end_station_name) AS null_end_name,
    COUNT(*) - COUNT(start_lat) AS null_start_lat,
    COUNT(*) - COUNT(start_lng) AS null_start_lng,
    COUNT(*) - COUNT(end_lat) AS null_end_lat,
    COUNT(*) - COUNT(end_lng) AS null_end_lng,
    COUNT(*) - COUNT(member_casual) AS null_cus_type
  FROM `data-analytics-case1.process.2211to2310-divvy-tripdata` 
)
UNPIVOT(value FOR field IN (
  num_row,
  null_ride_id,
  null_rideable_type,
  null_started_at,
  null_ended_at,
  null_start_id,
  null_start_name,
  null_end_id,
  null_end_name,
  null_start_lat,
  null_start_lng,
  null_end_lat,
  null_end_lng,
  null_cus_type
))
```

```{=html}
<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-fo1v{border-color:inherit;font-size:small;font-weight:bold;text-align:center;vertical-align:top}
.tg .tg-gqoj{border-color:inherit;font-size:small;text-align:right;vertical-align:top}
.tg .tg-oxjg{background-color:#f9f9f9;border-color:inherit;font-size:small;text-align:right;vertical-align:top}
.tg .tg-3wv3{background-color:#f9f9f9;border-color:inherit;font-size:small;text-align:left;vertical-align:top}
.tg .tg-5ece{border-color:inherit;font-size:small;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-fo1v">value</th>
    <th class="tg-fo1v">field</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-oxjg">5652827</td>
    <td class="tg-3wv3">num_row</td>
  </tr>
  <tr>
    <td class="tg-gqoj">0</td>
    <td class="tg-5ece">null_ride_id</td>
  </tr>
  <tr>
    <td class="tg-oxjg">0</td>
    <td class="tg-3wv3">null_rideable_type</td>
  </tr>
  <tr>
    <td class="tg-gqoj">0</td>
    <td class="tg-5ece">null_started_at</td>
  </tr>
  <tr>
    <td class="tg-oxjg">0</td>
    <td class="tg-3wv3">null_ended_at</td>
  </tr>
  <tr>
    <td class="tg-gqoj">866375</td>
    <td class="tg-5ece">null_start_id</td>
  </tr>
  <tr>
    <td class="tg-oxjg">866243</td>
    <td class="tg-3wv3">null_start_name</td>
  </tr>
  <tr>
    <td class="tg-gqoj">918937</td>
    <td class="tg-5ece">null_end_id</td>
  </tr>
  <tr>
    <td class="tg-oxjg">918796</td>
    <td class="tg-3wv3">null_end_name</td>
  </tr>
  <tr>
    <td class="tg-gqoj">0</td>
    <td class="tg-5ece">null_start_lat</td>
  </tr>
  <tr>
    <td class="tg-oxjg">0</td>
    <td class="tg-3wv3">null_start_lng</td>
  </tr>
  <tr>
    <td class="tg-gqoj">6759</td>
    <td class="tg-5ece">null_end_lat</td>
  </tr>
  <tr>
    <td class="tg-oxjg">6759</td>
    <td class="tg-3wv3">null_end_lng</td>
  </tr>
  <tr>
    <td class="tg-gqoj">0</td>
    <td class="tg-5ece">null_cus_type</td>
  </tr>
</tbody>
</table>
</center>
```
-   Total data size: 5,652,827
-   `NULL` values exist only in **station name**, **station id**, and **end coordinates**
    -   Over all `NULL` ratio is not high.
    -   Maybe the lack of station info is due to the location is not a predefined station.
    -   Number of `NULL` of **station id** is slightly higher than **station name**. Maybe some station only have name but no id?
    -   Need to find out why [6759 (\~0.1%)]{style="background-color: gold;"} trips lack end coordinates. Maybe they did not end at a station and customer mobile app also failed to acquire GPS data?

\

#### **2. Check for extra white space in strings**

Below query checks if any value in `ride_id` has extra white space.

```{sql, eval = FALSE}
SELECT  *
FROM
  (SELECT
    ride_id, TRIM(ride_id) AS trimmed
  FROM `data-analytics-case1.process.2211to2310-divvy-tripdata`
  )
WHERE ride_id <> trimmed
```

Output is empty, so `ride_id` is clean from extra white space.

Using the same method to check all string columns, we can find extra white space from `start_station_name` and `end_station_name` only.

Now we trim all the strings and save the result into a new table `trimmed-divvy-tripdata`. (`BigQuery SANDBOX` does not allow modification to the existing table.)

```{sql, eval = FALSE}
SELECT
  TRIM(ride_id) AS ride_id,
  TRIM(rideable_type) AS rideable_type,
  TRIM(start_station_id) AS start_station_id,
  TRIM(start_station_name) AS start_station_name,
  TRIM(end_station_id) AS end_station_id,
  TRIM(end_station_name) AS end_station_name,
  TRIM(member_casual) AS member_casual,
  started_at, ended_at, start_lat, start_lng, end_lat, end_lng
FROM `data-analytics-case1.process.2211to2310-divvy-tripdata`
```

\

#### **3. Is `ride_id` unique?**

```{sql, eval = FALSE}
SELECT
  COUNT(*) AS num_row,
  COUNT(DISTINCT ride_id) AS num_ride_id
FROM `data-analytics-case1.process.trimmed-divvy-tripdata`
```

```{=html}
<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-tcrt{font-family:Arial, Helvetica, sans-serif !important;text-align:center;vertical-align:top}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-dzk6{background-color:#f9f9f9;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-tcrt">Row</th>
    <th class="tg-baqh">num_row</th>
    <th class="tg-baqh">num_ride_id</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-dzk6">1</td>
    <td class="tg-dzk6">5652827</td>
    <td class="tg-dzk6">5652827</td>
  </tr>
</tbody>
</table>
</center>
```
The result confirms that `ride_id` is [unique]{style="background-color: gold;"} and works as [primary key]{style="background-color: gold;"} in this table. Though it may not be useful in this case study as we don't have other table to join with it.

\

#### **4. Start and end timing**

Trip end time should always be later than start time. Let's check if there is any data violating this rule:

```{sql, eval = FALSE}
SELECT COUNT(*)
FROM `data-analytics-case1.process.trimmed-divvy-tripdata`
WHERE started_at > ended_at
```

There are [239 (\~0.004%)]{style="background-color: gold;"} violations with end time **earlier** than start time. Similarly we can also find [898 (\~0.016%)]{style="background-color: gold;"} violations with end time **equal** to start time.

We are not sure the reason of these violations unless Cyclistic can help to check. But considering the ratio of issue data is quite small, it should NOT significantly skew our future analysis, so we will just leave them in this table.

\

#### **5. Bike type and customer type columns check**

```{sql, eval = FALSE}
SELECT DISTINCT rideable_type, member_casual
FROM `data-analytics-case1.process.trimmed-divvy-tripdata`
```

```{=html}
<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}
.tg .tg-dzk6{background-color:#f9f9f9;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-amwm">rideable_type</th>
    <th class="tg-amwm">member_casual</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-dzk6">classic_bike</td>
    <td class="tg-dzk6">casual</td>
  </tr>
  <tr>
    <td class="tg-baqh">classic_bike</td>
    <td class="tg-baqh">member</td>
  </tr>
  <tr>
    <td class="tg-dzk6">electric_bike</td>
    <td class="tg-dzk6">member</td>
  </tr>
  <tr>
    <td class="tg-baqh">docked_bike</td>
    <td class="tg-baqh">casual</td>
  </tr>
  <tr>
    <td class="tg-dzk6">electric_bike</td>
    <td class="tg-dzk6">casual</td>
  </tr>
</tbody>
</table>
</center>
```
There are 3 bike types and 2 customer types, looks good!

It is a surprise to find that `docked_bike` is only used by `casual` customer. Hmm... Since we cannot directly ask Cyclistic for the reason, let's wait and see if we can dig out anything in the next phase of the analysis.

\

#### **6. Station info consistency**

From number of `NULL` value we already know there is some issue in `station name` to `station id` matching. Now let's find out which one is more suitable to represent a specific station.

Let's find out issue station data with inconsistent name, id, or coordinates:

```{sql, eval = FALSE}
/* Generate temp tables */
/* start_station distinct (name, id) */
WITH start_station AS(
  SELECT DISTINCT name, id
  FROM(
    SELECT
      start_station_name AS name,
      start_station_id AS id
    FROM `data-analytics-case1.process.trimmed-divvy-tripdata` 
    WHERE
      /* remove rows with NULL on both (name, id) */
      start_station_name IS NOT NULL
      OR start_station_id IS NOT NULL
  )
), 
/* end_station distinct (name, id) */
end_station AS(
  SELECT DISTINCT name, id
  FROM(
    SELECT
      end_station_name AS name,
      end_station_id AS id
    FROM `data-analytics-case1.process.trimmed-divvy-tripdata` 
    WHERE
      end_station_name IS NOT NULL
      OR end_station_id IS NOT NULL
  )
),
/* combine start_station and end_station */
all_station AS(
  SELECT * FROM start_station
  UNION DISTINCT
  SELECT * FROM end_station
),
/* station name with more than 1 id (NULL included) */
extra_id AS(
  SELECT 
    DISTINCT name as station_name,
    COUNT(name) AS num_id
  FROM all_station
  GROUP BY name
  HAVING COUNT(name) > 1
),
/* station id with more than 1 name */
extra_name AS(
  SELECT 
    DISTINCT id as station_id,
    COUNT(id) AS num_name
  FROM all_station
  GROUP BY id
  HAVING COUNT(id) > 1
),
/* (name, id) of all issue stations */
suspicious_name_id AS(
  SELECT all_station.*
    FROM all_station
    INNER JOIN extra_name
    ON all_station.id = extra_name.station_id
  UNION DISTINCT
  SELECT all_station.*
    FROM all_station
    INNER JOIN extra_id
    ON all_station.name = extra_id.station_name
),
/* (name, id, lat, lng) of all issue stations*/
suspicious_station AS(
  SELECT station_info.*
  FROM(
    /* Union start and end stations */
    SELECT
      DISTINCT
      start_station_name AS name,
      start_station_id AS id,
      ROUND(start_lat, 1) AS lat,
      ROUND(start_lng, 1) AS lng
      FROM `data-analytics-case1.process.trimmed-divvy-tripdata`
      WHERE
        start_station_name IS NOT NULL
        OR start_station_id IS NOT NULL
    UNION DISTINCT
    SELECT
      DISTINCT
      end_station_name AS name,
      end_station_id AS id,
      ROUND(end_lat, 1) AS lat,
      ROUND(end_lng, 1) AS lng
      FROM `data-analytics-case1.process.trimmed-divvy-tripdata`
      WHERE
        end_station_name IS NOT NULL
        OR end_station_id IS NOT NULL
  ) AS station_info
  INNER JOIN suspicious_name_id
  ON
    (station_info.name = suspicious_name_id.name
     OR (station_info.name IS NULL AND suspicious_name_id.name IS NULL)
    ) AND
    (station_info.id = suspicious_name_id.id
     OR (station_info.id IS NULL and suspicious_name_id.id IS NULL)
    )
)

SELECT *
FROM suspicious_station
```

Above query generates 248 rows of output, which is exported to [Google Sheets]{style="background-color: lightgrey;"} ([[Link]{.underline}](https://docs.google.com/spreadsheets/d/1fCChOHzEmprXEF2w_NGFXl6H3oj4BD5h3m_qK3PKMgw/edit?usp=sharing)).

After manual processing, below are the key findings (refer to my [[working sheets]{.underline}](https://docs.google.com/spreadsheets/d/1fCChOHzEmprXEF2w_NGFXl6H3oj4BD5h3m_qK3PKMgw/edit?usp=sharing) for detail):

-   Several station names have tails like ` (temp)`. We can simply remove these tails.
-   Some typos are found, like `"Pubic"` and extra space between words. (SQL TRIM function only removes leading and tail spaces.)
-   Stations named as `"Public Rack - *"` tends to have duplicate id with other stations.
-   Some station id is likely missing the first 2 digits, e.g. `374` instead of `21374`.
-   Some station id is missing, can be filled with known id to the same name.
-   Some coordinates are missing or `0, 0`, can be replaced by other known coordinates according to station name and id.

From the sheet `"name id correction list"` I create a table `"station_correction"` in [BigQuery]{style="background-color: lightgrey;"}, which is used to clean station name and id data in below query.

```{sql, eval = FALSE}
SELECT
  t.ride_id AS ride_id,
  t.rideable_type AS bike_type,
  t.member_casual AS customer_type,
  t.started_at AS start_datetime,
  t.ended_at AS end_datetime,
  CASE /* start_station_name */
    WHEN c1.raw_name IS NOT NULL THEN c1.clean_name
    ELSE t.start_station_name
  END AS start_station_name,
  CASE /* start_station_id */
    WHEN c1.raw_name IS NOT NULL THEN c1.clean_id
    ELSE t.start_station_id
  END AS start_station_id,
  CASE /* end_station_name */
    WHEN c2.raw_name IS NOT NULL THEN c2.clean_name
    ELSE t.end_station_name
  END AS end_station_name,
  CASE /* end_station_id */
    WHEN c2.raw_name IS NOT NULL THEN c2.clean_id
    ELSE t.end_station_id
  END AS end_station_id,
  CASE /* start_lat */
    WHEN t.start_station_name = "Elizabeth St & Randolph St" 
      AND t.start_lat is NULL
      THEN 41.88355473
    WHEN t.start_station_name = "Green St & Madison Ave*" 
      AND t.start_lat = 0
      THEN 41.88182738
    WHEN t.start_station_name = "Stony Island Ave & 63rd St"
      AND (t.start_lat is NULL OR t.start_lat = 0)
      THEN 41.780506
    ELSE t.start_lat
  END AS start_lat,
  CASE /* start_lng */
    WHEN t.start_station_name = "Elizabeth St & Randolph St" 
      AND t.start_lat is NULL
      THEN -87.65912208
    WHEN t.start_station_name = "Green St & Madison Ave*" 
      AND t.start_lat = 0
      THEN -87.648831903934
    WHEN t.start_station_name = "Stony Island Ave & 63rd St"
      AND (t.start_lat is NULL OR t.start_lat = 0)
      THEN -87.586853
    ELSE t.start_lng
  END AS start_lng,
  CASE /* end_lat */
    WHEN t.end_station_name = "Elizabeth St & Randolph St" 
      AND t.end_lat is NULL
      THEN 41.88355473
    WHEN t.end_station_name = "Green St & Madison Ave*" 
      AND t.end_lat = 0
      THEN 41.88182738
    WHEN t.end_station_name = "Stony Island Ave & 63rd St"
      AND (t.end_lat is NULL OR t.end_lat = 0)
      THEN 41.780506
    ELSE t.end_lat
  END AS end_lat,
  CASE /* end_lng */
    WHEN t.end_station_name = "Elizabeth St & Randolph St" 
      AND t.end_lat is NULL
      THEN -87.65912208
    WHEN t.end_station_name = "Green St & Madison Ave*" 
      AND t.end_lat = 0
      THEN -87.648831903934
    WHEN t.end_station_name = "Stony Island Ave & 63rd St"
      AND (t.end_lat is NULL OR t.end_lat = 0)
      THEN -87.586853
    ELSE t.end_lng
  END AS end_lng,
FROM `data-analytics-case1.process.trimmed-divvy-tripdata` AS t
/* c1 is used to clean start_station name and id*/
LEFT OUTER JOIN `data-analytics-case1.process.station-correction` AS c1
ON t.start_station_name = c1.raw_name
/* c2 is used to clean end_station name and id*/
LEFT OUTER JOIN `data-analytics-case1.process.station-correction` AS c2
ON t.end_station_name = c2.raw_name
```

This result is saved as a new table `cleaned-divvy-tripdata`. If we check the station info again from this cleaned table, we can only find below id with 2 names: 

```{=html}
<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-x2zo{background-color:#f9f9f9;font-size:small;text-align:left;vertical-align:top}
.tg .tg-j9os{font-size:small;font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-5qt9{font-size:small;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-j9os">name</th>
    <th class="tg-j9os">id</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-x2zo">Fort Dearborn Dr &amp; 31st St*</td>
    <td class="tg-x2zo">chargingstx06</td>
  </tr>
  <tr>
    <td class="tg-5qt9">Loomis St &amp; Lexington St*</td>
    <td class="tg-5qt9">chargingstx06</td>
  </tr>
  <tr>
    <td class="tg-x2zo">Wentworth Ave &amp; Cermak Rd*</td>
    <td class="tg-x2zo">chargingstx07</td>
  </tr>
  <tr>
    <td class="tg-5qt9">Green St &amp; Madison Ave*</td>
    <td class="tg-5qt9">chargingstx07</td>
  </tr>
</tbody>
</table>
</center>
```

We have no more info from the raw data to correct these id, so just leave as they are. All the station names are unique now and can be used as key to station if necessary.

Now we can check if there is any station [appear only at trip start or end]{style="background-color: gold;"}:

```{sql, eval = FALSE}
WITH start_only AS(
  SELECT start_station_name
  FROM `data-analytics-case1.process.cleaned-divvy-tripdata`
  EXCEPT DISTINCT
  SELECT end_station_name
  FROM `data-analytics-case1.process.cleaned-divvy-tripdata`
  ORDER BY start_station_name
),
end_only AS(
  SELECT end_station_name
  FROM `data-analytics-case1.process.cleaned-divvy-tripdata`
  EXCEPT DISTINCT
  SELECT start_station_name
  FROM `data-analytics-case1.process.cleaned-divvy-tripdata`
  ORDER BY end_station_name
),
trips_from_start_only AS(
  SELECT trips.start_station_name, trips.start_station_id, COUNT(*) AS n
  FROM `data-analytics-case1.process.cleaned-divvy-tripdata` AS trips
  INNER JOIN start_only
  ON trips.start_station_name = start_only.start_station_name
  GROUP BY trips.start_station_name, trips.start_station_id
),
trips_to_end_only AS(
  SELECT trips.end_station_name, trips.end_station_id, COUNT(*) AS n
  FROM `data-analytics-case1.process.cleaned-divvy-tripdata` AS trips
  INNER JOIN end_only
  ON trips.end_station_name = end_only.end_station_name
  GROUP BY trips.end_station_name, trips.end_station_id
)

SELECT
  "start_station" AS type,
  start_station_name AS station_name,
  start_station_id AS station_id,
  n
FROM trips_from_start_only
UNION DISTINCT
SELECT "end_station", *
FROM trips_to_end_only
```

The result is exported to [Google Sheets]{style="background-color: lightgrey;"} ([[Link]{.underline}](https://docs.google.com/spreadsheets/d/1JDWKpYV22EErLbhh5DwKTmFX7fsAkh3Wd84C7PrGaSY/edit#gid=806829325)) and the summary is shown below:

```{=html}
<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-we42{background-color:#D9E0E8;border-color:#003532;font-size:small;font-style:italic;text-align:left;vertical-align:bottom}
.tg .tg-onz4{background-color:#6883A4;border-color:#003532;color:#FFF;font-size:small;text-align:left;vertical-align:bottom}
.tg .tg-l4gq{background-color:#F2F5F7;border-color:#003532;font-size:small;text-align:left;vertical-align:bottom}
.tg .tg-ow7p{background-color:#FFF;border-color:#003532;font-size:small;text-align:right;vertical-align:bottom}
.tg .tg-rg9e{background-color:#D9E0E8;border-color:#003532;font-size:small;font-weight:bold;text-align:left;vertical-align:bottom}
.tg .tg-wiaf{background-color:#D9E0E8;border-color:#003532;font-size:small;font-weight:bold;text-align:right;vertical-align:bottom}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-we42"><span style="font-style:italic;background-color:#D9E0E8">type</span></th>
    <th class="tg-onz4"><span style="color:#FFF;background-color:#6883A4">Unique stations</span></th>
    <th class="tg-onz4"><span style="color:#FFF;background-color:#6883A4">SUM of trips</span></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-l4gq"><span style="background-color:#F2F5F7">start_station</span></td>
    <td class="tg-ow7p"><span style="background-color:#FFF">16</span></td>
    <td class="tg-ow7p"><span style="background-color:#FFF">27</span></td>
  </tr>
  <tr>
    <td class="tg-l4gq"><span style="background-color:#F2F5F7">end_station</span></td>
    <td class="tg-ow7p"><span style="background-color:#FFF">27</span></td>
    <td class="tg-ow7p"><span style="background-color:#FFF">34</span></td>
  </tr>
  <tr>
    <td class="tg-rg9e"><span style="font-weight:bold;background-color:#D9E0E8">Grand Total</span></td>
    <td class="tg-wiaf"><span style="font-weight:bold;background-color:#D9E0E8">43</span></td>
    <td class="tg-wiaf"><span style="font-weight:bold;background-color:#D9E0E8">61</span></td>
  </tr>
</tbody>
</table>
</center>
```

Though still not clear why these stations only appear at start or end of all trips, but the number of trips associate with them is quite small, so shall not significantly affect future analysis.

\

------------------------------------------------------------------------

###### 

We have cleaned the data and checked its integrity. Now we are ready to do data transformation and analysis, just need to take note that the data still has below small issues:

1.  Not all station info exist.
2.  \~0.1% trips lack end coordinates.
3.  \~0.02% trips end time is equal or earlier than start time.
4.  2 station id(s) are not unique, but all station names are unique and can be used as key to station if necessary.
5.  A few stations only appear at start of end of all trips, but the total number of trips to or from them is small.

\
